{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b04d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from doctomarkdown import DocToMarkdown\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4d7648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number: 1 | Page Content: Sayantan Ghosh\n",
      "Consultant Data Scientist – Applied AI\n",
      "Kolkata, West Bengal\n",
      "Tel: +91 6290200929\n",
      "Email : sayantghosh@deloitte.com\n",
      "Career Highlights\n",
      "Profile\n",
      "• Frameworks: Scikit, darts, tensorflow, keras, langchain,\n",
      "llamaindex, NLTK, SpaCy, Keras, Flask, Streamlit, tpot, langgraph,\n",
      "CrewAI\n",
      "• Tools: Huggingface, Git,Databricks, Azure Ml Studio, Azure\n",
      "Document Intelligence, Azure functions, Azure Kubernetes Service,\n",
      "PowerBI, tableau, AWS (Amazon Web Services), Amazon Sagemaker\n",
      "• Platforms: Web, Windows, Azure, AWS\n",
      "• Soft Skills: Leadership, Event Management, Public Speaking, Time\n",
      "Management\n",
      "Skillsets\n",
      "Research Publications\n",
      "Book Chapter: Detection of Coronavirus (COVID-19) Using Deep\n",
      "Convolutional Neural Networks with Transfer Learning Using Chest\n",
      "X-Ray Images): Published in Studies in Computational Intelligence\n",
      "2021\n",
      "• MLAI: An Integrated Automated Software Platform to Solve\n",
      "Page Number: 2 | Page Content: Machine Learning Problems):\n",
      "Work Experience\n",
      "US Based Consulting Firm Kolkata, West Bengal\n",
      "Consultant - Data Scientist (Full-time) 2.1 year\n",
      "◦ GenAI Projects: The Sphere AI-enabled Tax Co-Pilot System:\n",
      "Leading the Sphere project driving $2+ million. Utilized Advanced\n",
      "RAG pipeline using Langchain to build a multi-agent orchestration\n",
      "agent pool system using Langgraph, and Prompting Strategies\n",
      "like Chain Of Thoughts, Tree Of Thoughts to solve complex client\n",
      "deliverables, etc.\n",
      "Tech Stacks : Langgraph, Langchain, Crew AI, RAG, Azure, Fast API\n",
      "◦ Time Series Forecasting: Engineered a scalable, dynamic time\n",
      "series forecasting pipeline for demand prediction.\n",
      "Employing ensemble modeling techniques such as AutoARIMA,\n",
      "tbats, and SARIMAX, the pipeline harnessed metrics\n",
      "including AIC and MAPE. This approach yielded a notable\n",
      "benchmark achievement, showcasing a remarkable 70%\n",
      "enhancement in MAPE score.\n",
      "Tech Stacks : Time Series, darts, ARIMA\n",
      "◦ Deployed a scalable custom text extraction engine for unstructured\n",
      "documents (IRS, K1, K3 forms) using\n",
      "Page Number: 3 | Page Content: Detectron2 and Tesseract, leveraging Azure Service Bus Azure\n",
      "functions in AKS. Realized an impressive 80% reduction in\n",
      "extraction time overall for 1000+ IRS forms extraction.\n",
      "◦ Designed & Deployed InfoMINER, an NLP-based custom Question-\n",
      "Answering and Language Translation app using\n",
      "LLMs, Vector Store, OpenAI for documents, harnessing the power of\n",
      "the Langchain framework, Generative Pretrained\n",
      "Transformers, and transformers.\n",
      "◦ IRS Document Classification & Extraction : Implemented an end-\n",
      "to-end ViT (Vision Transformer) Model - LayoutLM-v2\n",
      "for document classification, achieving benchmark accuracy of\n",
      "97.5% on 18 complex document Classes.\n",
      "Tech Stacks : Detectron 2, Layout LM, pytorch\n",
      "Projects\n",
      "✅ PdfMinerv1.0 - Contextual Question Answering from Documents\n",
      "using Langchain): Designed an AI-enabled Conversational Chat-bot\n",
      "using a custom knowledge base(Documents, CSV) using vector db,\n",
      "retrieval pipeline from Langchain. Designed the frontend using the\n",
      "Chainlit UI framework.Compared the results using OpenAI and\n",
      "open-source LLM models.\n",
      "✅AutoScan - Text Extraction Application): (Github Repo) This is\n",
      "an automatic Business Cards’ Text Extraction &\n",
      "Labeling Application. BIO Tagging is used to prepare the training\n",
      "data and trained using Spacy NER Model. Handled Low\n",
      "Quality Unstructured Images using high level Data Preprocessing\n",
      "techniques.\n",
      "Page Number: 4 | Page Content: Results-driven Data Scientist with 4+ years of relevant experience\n",
      "specializing in Generative AI, Azure ML, and ML solution design.\n",
      "Proficient in developing and deploying scalable applications on\n",
      "Azure, leading to optimized operational efficiency. Skilled in\n",
      "leveraging cutting-edge technologies in Machine learning, Deep\n",
      "Learning, and NLP.\n",
      "• Expertise in NLP,BERT, Sentiment Analysis, Topic Modeling, RAG\n",
      "Architecture, Prompt Engineering.\n",
      "• Proficient in Prompting Techniques(CoT,ToT) for Np-hard\n",
      "problems, including RAG using Langchain framework, VectorDB,\n",
      "Embedding, and Information Retrieval from unstructured\n",
      "documents.\n",
      "• Strong understanding of Statistics, classical ML concepts,\n",
      "Xgboost,GBM Ensemble approach,\n",
      "Optimizations, and deep learning algorithms.\n",
      "• Experienced in Azure ML Platform for designing and deploying\n",
      "highly scalable systems in a Microservices architecture (Service Bus,\n",
      "Azure Functions).\n",
      "• Skilled in Open Source LLM finetuning (PEFT, LoRA) and\n",
      "Transformer architectures.\n",
      "• Top 5% Rank holder in ML/DL Hackathons. (Hackerearth)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = DocToMarkdown()\n",
    "\n",
    "result = app.convert_pdf_to_markdown(\n",
    "    filepath=\"sample_docs/sample-ppt-1.pptx\",\n",
    "    extract_images=True,\n",
    "    extract_tables=True,\n",
    "    output_path=\"markdown_output\"\n",
    ")\n",
    "\n",
    "for page in result.pages:\n",
    "    print(f\"Page Number: {page.page_number} | Page Content: {page.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e253c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
